**Instruction-level Parallelism**
- Pipelining - keep all resources in processor busy during clock cycles by overlapping elements of the fetch-decode-execute cycle
- Superscalar processing - execute multiple independent instructions in one clock cycle
- Implemented in hardware on all modern processors
![[Pasted image 20251118130608.png|centre|400]]
Becomes:
![[Pasted image 20251118130629.png|centre|400]]
**Data-level parallelism (SIMD/Vectorisation)**
- Use extra-wide registers and arithmetic units to perform the same instruction on multiple data elements simultaneously
- Implemented in all modern processors
- Vector instructions generated by most compilers - but limited in where it can be applied, may still need some code modification.

**Shared-memory (Thread-level/multi-core) parallelism**
- Execute multiple threads on multiple cores within a single processor
- All threads have access to the same memory
- Limited scalability to number of cores on one machine
- Requires manual implementation from the programmer (pythreads, openmp)

**Distributed-memory parallelism**
- Execute multiple copies (instances) of program on multiple cores - instances do not have to be on the same machine
- Memory is segregated between instances: explicit communication required to transfer data or synchronise instances
- Scalable to very large number of instances
- Complex programmer implementation (MPI)
